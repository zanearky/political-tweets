---
title: "How Controversy and Sentiment Shaped Twitter Engagement in 2020 US Election Narratives"
shorttitle: "Paper"
abstract: "This study examines drivers of engagement on Twitter in pro-democracy and election fraud narratives during weeks surrounding the 2020 US Presidential Election. Analyzing 14,553 tweets, we employed a reggression analysis to measure the impact that different factors like content, user characteristics, and engagement metrics had on overall engagement within the political discourse space. Our findings show that while retweets and likes are universal predictors, the retweet-to-like ratio, interpreted as a proxy for controversy, is a consistent significant predictor of driving engagement across both narratives, with significant interactions with descriptions of tweet content. Different dynamics are revealed: in pro-democracy discourse displayed positive sentiment, even when associated with Trump, while election fraud discourse displayed overwhelmingly negative sentiments, and less positive sentiment associated with Trump. This research reveals a nuanced mechanism of users across the political spectrum engage with controversial political discourse on Twitter."
keywords: [Twitter, Political Discourse]
thanks: Thanks to everyone for checking this out.
reference-section-title: References
bibliography: ../bibliography/project.bib
csl: ../bibliography/chicago-parenthetical.csl
format:
  aog-article-pdf:
    keep-tex: false
    include-in-header: 
      text: |
        \usepackage{dcolumn}
#  submittable-pdf:
#     keep-tex: false
#     fig-pos: "!t"
#     include-in-header: 
#       text: |
#         \usepackage{dcolumn}
  submittable-docx: default
---

```{r}
#| label: setup
#| include: false
library(here)
source(here("utils","check_packages.R"))
source(here("utils","functions.R"))

load("data/data_constructed/election_fraud.RData")
load("data/data_constructed/democracy.RData")
```

# Introduction

Since its emergence in 2006, Twitter has evolved from a microblogging platform into a global space for real-time political discourse, news dissemination, and public engagement. Unlike other social networking sites (SNS), Twitter uniquely decentralizes control of discourse: users shape discoursethrough organic interactions like hashtags, mentions, and retweets, while algorithms amplify content based on opaque engagement metrics. This paper examines how these dynamics played out during the 2020 U.S. Presidential Election by analyzing two opposing narratives: #democracy (positive, pro-system) and #electionfraud (negative, anti-system). During election week, the use of hashtags connected these narratives together to become a battleground for political discourse. Each narrative centers around both candidates simultaneously, with the use of their names in mentions, tweet text, and hashtags appearing as prevalent throughout both  spaces. Tweets in both narratives have sentimental language. In this paper we ask specifically: Does political controversy create similar reactions across a polarized political online space? Understanding mechanisms, specifically sentiment, which form a narrative frame out of a response to controversy is critical to decoding how political discourse polarizes and influences public perception in social media spaces.

# Background

There has been much research on the social impact of SNS platforms, particularly Twitter and its sensationalist attitudes. On Twitter, users have always played a fundamental and organic role in shaping how content is organized on the platform. Twitter’s infrastructure of hashtags, retweets, and mentions was originally used by users to organize content [@papacharissi2012affective]. Retweets act as social endorsements that amplify ideologies, while likes personalize engagement, creating different incentives for engagement and virality [@papacharissi2012affective]. 

***H1: Higher retweet-to-like ratios, as indicators of controversy, will positively predict tweet engagement, and this relationship will be moderated by specific political narratives (pro-democracy vs. election fraud discourse).***

Prior work shows that like-to-retweet ratios could be a useful indicator of civility in political spaces, distinguishing incivility in tweets as amplified (retweeted) in higher relative amounts than they were endorsed (liked), and ultimately rewarded for spreading outrage [@frimer2023incivility]. We want to extend from this, and test if the nature of the relationship between outrage and engagement is moderated differently in different political narratives. Less work has been done to study this effect along political divisions: we greatly increase the appearances of political controversy by focusing on this election, which helps us study this relationship.

***H2: Distinct political spaces have distinct emotional dynamics.***

[@brady2019effective] determines that moral outrage can motivate collective group behavior, but at a cost of rational discourse, with any dissident voices being drowned out. It is important to understand not only how political division creates engagement, but what the cost of this division is. H2 is explored by observing differences in the effects of sentiment coefficients. Specifically, we assume to observe different sentiment interactions with engagement metrics and candidate mentions between different political discourses. Our study extends from past research by modeling subtle interactions between retweet-to-like ratios, account influence (log(followers)), candidate mention, sentiment, and engagement metrics in #democracy and #electionfraud discourse. By doing so, we reveal how emotional framing shifts between different political narratives.

# Data and Methods

The dataset in this paper consists of 16450 tweets collected between October 16th, 2020 to November 9th, 2020, during the final weeks leading up to and from the week after the 2020 US Presidential Election.  The tweets were collected using the Twitter API statuses_lookup and snsscrape for keywords. The data were scraped by a third party and are publicly available on Kaggle: [US Election 2020 Tweets](https://www.kaggle.com/datasets/manchunhui/us-election-2020-tweets/data).

The dataset contains 21 columns and records metadata such as tweet text, timestamp, user ID, various engagement metrics such as follower count, likes, and retweets. Our study focuses on tweet content, engagement metrics of likes, retweets, and a retweet-per-like ratio.

User follower counts, likes, and retweets are all highly right-skewed. User follower counts exhibit the most skew with a median of 966 and IQR = 3722. The 95th percentile reaches 42716, indicating significant skew and a high presence of smaller, non-elite users. To adjust for this, we log transform user follower counts, likes, and retweets in all of our models and visualizations. The retweet-to-like ratio represents a ratio of the non-log transformed engagement metrics. We use a retweet-to-like ratio as a metric for tweet controversy. This is inspired by previous work [@frimer2023incivility], that linked higher like-to-retweet ratios to more civil tweets in political discourse. While we don't test this claim in our study directly, we invert the logic to interpret that high retweet-to-like ratios are indicative of tweets which are highly amplified but not as widely endorsed, consonant with patterns of controversial tweets. A visual inspection of tweets with low and high retweet-to-like ratios in our dataset supported this interpretation, though it is important to note that this interpretation is not proven in our data set substantively. 

An engagement weight is assigned to each tweet, that classifies it as being in either the 99th, 95th, 90th or below 90th percentile based on the amount of likes and retweets in has, assigning a double from 10 to 0.01, repesectively. Percentiles are listed in @tbl-1 below. 

```{r}
#| label: tbl-1
#| tbl-cap: "Tweet Engagement Percentile Thresholds and Assigned Weights"

engagement_table_data <- data.frame(
  Percentile = c("99th Percentile and Above",
                 "95th Percentile to 99th Percentile",
                 "90th Percentile to 95th Percentile",
                 "Below 90th Percentile"),
 `Total Engagement Threshold` = c(
    "likes >= 234 or retweet count >= 88",
    "likes >= 26 or retweet_count >= 9",
    "likes >= 11 or retweet_count >= 4",
    "likes < 11 and retweet count < 4"
  ),
  `Assigned Weight` = c(10.00, 1.00, 0.10, 0.01)
)

knitr::kable(
  engagement_table_data,
  align = c("l", "c", "c"), 
  digits = 2)

```

The dataset contained tweets from multiple countries, regions, and languages, and we filtered out tweets whose core text was not in English using the detect_language() function from the cld3 R package [@cld3].

We focused on two opposing political narratives which were assigned a group of hashtags and phrases based off of analysis using a k-means clustering algorithm [@stewart2021projects] and clustered hashtags in the data around the chosen hashtags of #democracy and #electionfraud. We found that Joe Biden's name and campaign tags were closely associated with pro-democracy hashtags, while variants of Donald Trump campaign hashtags and maga hashtags were closely tied to various election fraud hashtags. There was small overlap in hashtags used in both spaces. We chose a small groups of hashtags clustered closely to the respective narratives which we found were most relevant to the either the democracy or election fraud discourse.

- Pro-democracy hashtags include: #democracy, #counteveryvote, #countallthevotes, and #everyvotecounts. 
- Election Fraud hashtags include: #electionfraud, #voterfraud, #fraud, #stopthesteal, #corruption, #rigged, and #counteverylegalvote.
  
We collected tweets in the data based on the detection of these signifiers in either the hashtags or as phrases in the core tweet text. 

For bot cleaning, we conducted a simple heuristic method that matched and filtered tweets that consisted (1) solely of urls, (2) solely of hashtags, or (3) contained fewer than 10 characters. This method is based on previous work which suggests that these attributes are reliable indicators of bot spamming [@inuwa2018lexical]. Additionally, we removed all tweets which contained less than five words in the core tweet text, excluding trailing hashtags. This reduced the the dataset to a much cleaner sample of tweets with substantive language. 

From the sample of 14553 tweets, 7402 were captured on democracy mentions, while 7151 were captured on election fraud mentions. Tweets in either space are all distinct from each other, and we did not include tweets which mention both democracy and election fraud. We excluded these tweets that mentioned both narratives in order to reduce semantic overlap and clarify boundaries between the groups. This allows us to separate trends in sentiment and engagement without worrying about conflation of these aspects from separate discourse spaces (i.e. trolls injecting their message and sentiment into the opposing group's discourse space). We also only included tweets which mentioned biden, trump, or neither in the tweet text, excluding trailing hashtags. We excluded tweets that mentioned both because our focus relies on a clear, separate picture of how candidates affect engagement in different discourses. 

This study is subject to several limitations related to the scope of the data and the way in which data was collected. Tweets were collected based on the keywords "Biden" and "Trump," which means tweets in this data set are limited only to content that explicitly mentions these names. We also exclude overlap between narrative tags of democracy and election fraud. As a result, the data set is missing political discourse connected to either democracy or election fraud narratives. It is a possibility that the data under represents both broader and more specific political discussions around these topics. Second, the data is limited to the time period of a month (between October 16th and November 9th). While this window captures a valuable sample of a peak in political discourse on Twitter directly related to election narratives, it misses a long-term picture of how these political narratives developed, as well as continued to shift narratively, and in their framing. These constraints should be kept in mind and considered when interpreting the results, particularly in regards to interpreting narrative shifts and engagement patterns. 

# Results

Figures 2 and 3 reveal distinct and diverging emotional landscapes between political discourses. Emerging trends show how different discourses engage with political controversy differently. 

```{r}
#| label: fig-1
#| fig-cap: "*Retweet:Like Ratio by Log Transformed Retweet Count.* Note: opacity of the points indicates the engagement weight of the tweet*"

p1 <- ggplot(data = democracy, aes(x = retweet_like_ratio, y = log1p(retweet_count))) +
  geom_point(aes(color = sent_direction,
                 alpha = engagement_weight)) +
  scale_alpha_continuous(range = c(0.1,5)) +
  labs(title = "Democracy Discourse",
       x = "Retweet:Like Ratio",
       y = "Retweet Counts (logged)") +
  theme(legend.title = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(size = 7),  
        axis.title = element_text(size = 10),  
        axis.text = element_text(size = 9)) +
  facet_wrap(~mentions)


p2 <- ggplot(data = election_fraud, aes(x = retweet_like_ratio, y = log1p(retweet_count))) +
  geom_point(aes(color = sent_direction, 
                 alpha = engagement_weight)) +
  scale_alpha_continuous(range = c(0.1, 5)) +
  labs(title = "Election Fraud Discourse",
       x = "Retweet:Like Ratio",
       y = "Retweet Counts (logged)") +
  theme(legend.title = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(size = 7),  
        axis.title = element_text(size = 10),  
        axis.text = element_text(size = 9)) +
  facet_wrap(~mentions)

(p1 + p2) + plot_layout(guides = "collect") 


```
@fig-1 shows that sentiment trends in the democracy and election fraud discourse spaces move in opposite directions. It's notable how democracy discourse exhibits a higher overall positive sentiment, even in Trump mentions. Specifically in democracy discourse, positive Biden mentions with lower controversy tend to correlate with high engagement, while overall, uncontroversial and positive sentiment looks to drive engagement in democracy discourse. Conversely, Biden mentions in election fraud discourse are overwhelmingly negative, and tend to draw high retweet-to-like ratios, as well as high in engagement. Trump mentions in both discourse spaces tend to look more positive when they have higher retweet-to-like ratios, which could mean mentiong Trump with positive sentiment is likely to be controversial. Most of the outliers across all graphs which are highest in engagement are negative in sentiment regardless of candidate mention or discourse, while at the same time not indicating controversy. This suggests the presence of elite accounts with large followings, who receive amplification and endorsements regardless of what they post. The converging negative sentiment in mentions of Biden in election fraud discourse is not reflected in Trump mentions in democracy discourse. Furthermore, across discourses the groupings in Trump mentions in election fraud discourse are not as uniformly positive as Biden mentions in the democracy graph. @fig-2 further explores relationships between follower counts, tweet controversy, and sentiment direction shaping engagement. 
```{r}
#| label: fig-2
#| fig-cap: "*Log Transformed Follower Counts by Retweet:Like Ratio.* Note: opacity of the points indicates the engagement weight of the tweet."

p3 <- ggplot(data = democracy, aes(x = log1p(user_followers_count), y = retweet_like_ratio)) +
  geom_point(aes(color = sent_direction,
                 alpha = engagement_weight)) +
  scale_alpha_continuous(range = c(0.1,5)) +
  labs(title = "Democracy Discourse",
       x = "User Follower Counts (logged)",
       y = "Retweet:Like Ratio") +
  theme(legend.title = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(size = 7),  
        axis.title = element_text(size = 10),  
        axis.text = element_text(size = 9)) +
  facet_wrap(~mentions)


p4 <- ggplot(data = election_fraud, aes(x = log1p(user_followers_count), y = retweet_like_ratio)) +
  geom_point(aes(color = sent_direction, 
                 alpha = engagement_weight)) +
  scale_alpha_continuous(range = c(0.1, 5)) +
  labs(title = "Election Fraud Discourse",
       x = "User Follower Counts (logged)",
       y = "Retweet:Like Ratio") +
  theme(legend.title = element_text(size = 8),
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(size = 7),  
        axis.title = element_text(size = 10),  
        axis.text = element_text(size = 9)) +
  facet_wrap(~mentions)

(p3 + p4) + plot_layout(guides = "collect") 


```
@fig-2 shows a clear trend of how elite accounts, characterized by higher follower counts, show significantly more controversial and engaging content. These effects look strongest in Biden mentions across both discourses. It's also notable how much fewer small accounts with fewer followers mention Biden in democracy discourse than in election fraud discourse for both Trump and Biden mentions.  This same effect is not as clear for Trump mentions across both areas of discourse. Democracy discourse maintains an overall positive sentiment across all candidate mentions, while election fraud maintains to be mainly negative. Although Trump mentions in election fraud discourse are an exception, where sentiment and engagement patterns are less distinct: comparable to election fraud discourse which mentions neither candidate. Interestingly, election fraud discourse which mentions either Trump or neither candidate looks relatively high in neutral sentiment. A deeper regression analysis further clarifies mechanisms through which elite accounts drive controversy and engagement across political discourse spaces.

```{r}
#| label: tbl-2
#| tbl-cap: "*Regression Coefficients for Engagement in Democracy Discourse.* Note: models assume Biden and negative sentiment as a reference."

dem_models <- list(model_1 =  lm(log1p(retweet_count) ~ retweet_like_ratio + mentions + log1p(user_followers_count) + log1p(likes), data = democracy),
                   model_2 = lm(log1p(retweet_count) ~ (retweet_like_ratio * sent_direction) + mentions + log1p(user_followers_count) + log1p(likes), data = democracy), 
                   model_3 = lm(log1p(retweet_count) ~ (retweet_like_ratio*log1p(user_followers_count)) +  (retweet_like_ratio*sent_direction)+(mentions*log1p(user_followers_count)) + (sent_direction*log1p(user_followers_count)) + log1p(likes), data = democracy),
                   model_4 = lm(log1p(retweet_count) ~ (retweet_like_ratio*log1p(user_followers_count)) + (retweet_like_ratio*sent_direction) + (mentions*log1p(user_followers_count))  + (sent_direction*log1p(user_followers_count)) + (mentions*sent_direction)  + log1p(likes), data = democracy))

modelsummary(dem_models, 
                             output = "gt",
                             stars = TRUE,
                             coef_map = c(
                               "retweet_like_ratio" = "Retweet:Like Ratio",
                               "mentionstrump" = "Mentioned Trump",
                               "mentionsneither" = "Mentioned Neither",
                               "log1p(user_followers_count)" = "Logged Followers",
                               "log1p(likes)" = "Logged Likes",
                               "sent_directionneutral" = "Neutral Sentiment",
                               "sent_directionpositive" = "Positive Sentiment",
                              "retweet_like_ratio:sent_directionneutral" = "Retweet:Like Ratio × Neutral Sentiment",
  "retweet_like_ratio:sent_directionpositive" = "Retweet:Like Ratio × Positive Sentiment",
  "retweet_like_ratio:log1p(user_followers_count)" = "Retweet:Like Ratio × Logged Followers",
  "log1p(user_followers_count):mentionsneither" = "Logged Followers × Neither Mentioned",
  "log1p(user_followers_count):mentionstrump" = "Logged followers × Trump Mentioned",
  "log1p(user_followers_count):sent_directionneutral" = "Logged followers × Neutral Sentiment",
  "log1p(user_followers_count):sent_directionpositive" = "Logged followers × Positive Sentiment",
  "sent_directionneutral:mentionsneither" = "Neutral Sentiment x Neither Mentioned",
  "sent_directionpositive:mentionsneither" = "Positive Sentiment x Neither Mentioned",
  "sent_directionneutral:mentionstrump" = "Neutral Sentiment x Trump Mentioned",
  "sent_directionpositive:mentionstrump" = "Positive Sentiment x Trump Mentioned"
                               )
)

```

As shown in @tbl-2, our models predict a high amount of variance in logged retweets (in model 4, Adjusted R2 $\approx$ 0.80), and improves from model 1 to model 4 with the addition of interaction terms, with model 4 being the best fit overall. We see the retweet-to-like ratio being highly significant across all models. While declining from (1.800 HS) to (0.676 HS) when interaction terms are introduced in model 4, the impact of the retweet-to-like ratio is spread out to its interaction with logged followers, though its individual effect still strongly predicts logged retweets. As we would expect, logged followers count and logged likes are similarly strong positive predictors of logged retweets across all models. In model 4 we see how elite accounts (retweet:like x logged followers) amplify controversy (0.139 HS). The strong positive interaction between Trump mentions and positive sentiment (0.102 HS) suggests an interesting effect of positive Trump mentions driving up retweets in pro-democracy discourse. This might be explained by the significant interaction of retweet-to-like ratio with positive sentiment, which has a positive effect on increased retweets (0.145 S). We can compare these results with the same models fit to the election fraud data. 

```{r}
#| label: tbl-3
#| tbl-cap: "*Regression Coefficients for Engagement in Election Fraud Discourse.* Note: models assume Biden and negative sentiment as a reference."

fraud_models <- list(model_1 =  lm(log1p(retweet_count) ~ retweet_like_ratio + mentions + log1p(user_followers_count) + log1p(likes), data = election_fraud),
                   model_2 = lm(log1p(retweet_count) ~ (retweet_like_ratio * sent_direction) + mentions + log1p(user_followers_count) + log1p(likes), data = election_fraud), 
                   model_3 = lm(log1p(retweet_count) ~ (retweet_like_ratio*log1p(user_followers_count)) +  (retweet_like_ratio*sent_direction)+(mentions*log1p(user_followers_count)) + (sent_direction*log1p(user_followers_count)) + log1p(likes), data = election_fraud),
                   model_4 = lm(log1p(retweet_count) ~ (retweet_like_ratio*log1p(user_followers_count)) + (retweet_like_ratio*sent_direction) + (mentions*log1p(user_followers_count))  + (sent_direction*log1p(user_followers_count)) + (mentions*sent_direction)  + log1p(likes), data = election_fraud))

modelsummary(fraud_models, 
                               output = "gt",
                               stars = TRUE,
                             coef_map = c(
                               "retweet_like_ratio" = "Retweet:Like Ratio",
                               "mentionstrump" = "Mentioned Trump",
                               "mentionsneither" = "Mentioned Neither",
                               "log1p(user_followers_count)" = "Logged Followers",
                               "log1p(likes)" = "Logged Likes",
                               "sent_directionneutral" = "Neutral Sentiment",
                               "sent_directionpositive" = "Positive Sentiment",
                              "retweet_like_ratio:sent_directionneutral" = "Retweet:Like Ratio × Neutral Sentiment",
  "retweet_like_ratio:sent_directionpositive" = "Retweet:Like Ratio × Positive Sentiment",
  "retweet_like_ratio:log1p(user_followers_count)" = "Retweet:Like Ratio × Logged Followers",
  "log1p(user_followers_count):mentionsneither" = "Logged Followers × Neither Mentioned",
  "log1p(user_followers_count):mentionstrump" = "Logged followers × Trump Mentioned",
  "log1p(user_followers_count):sent_directionneutral" = "Logged followers × Neutral Sentiment",
  "log1p(user_followers_count):sent_directionpositive" = "Logged followers × Positive Sentiment",
  "sent_directionneutral:mentionsneither" = "Neutral Sentiment x Neither Mentioned",
  "sent_directionpositive:mentionsneither" = "Positive Sentiment x Neither Mentioned",
  "sent_directionneutral:mentionstrump" = "Neutral Sentiment x Trump Mentioned",
  "sent_directionpositive:mentionstrump" = "Positive Sentiment x Trump Mentioned"
                               )
  )

```
Across all 4 models in @tbl-3, R2 remains consistently high (in model 4, Adjusted R2 $\approx$ 0.83), and logged likes, logged followers, and retweet-to-like ratio remain strong predictors of logged retweets, as well as many of the significant interaction terms in democracy discourse models remaining significant. However, many of ther interaction term's effects of are now diminished: The effect of elite accounts amplifying controversy to drive up retweets (retweet:like x logged followers) is much less (0.076 HS) compared to (0.139 HS) democracy models. Positive or neutral Trump mentions (positive sentiment x Trump mentioned) do not drive up retweets as much as they do in democracy discourse (0.076 S compared to 0.102 HS), along with controversial positive sentiment to that seen in democracy models (0.145 S compared to 0.048 NS). Instead, the retweet-to-like ratio (0.936 HS) and logged likes (0.634 HS) have higher effects in the election fraud models as strong predictors of engagement, and their influence is less spread out among interaction terms.

# Conclusions

This study investigated the dynamics of online political discourse surrounding the 2020 US Presidential Election, specifically focusing on two related and opposing political narratives of pro-democracy and election fraud and how they impact engagement. We analyzed a substantial dataset of cleaned tweets and employed robust regression models to find key factors which drove engagement in these distinct discourse spaces. 

Our findings consistently show that tweet engagement is driven by Twitter's engagement dynamics of user follower counts, likes, and retweet-to-like ratios emerging as highly significant positive predictors across all models and in both narrative contexts. The high adjusted R2 scores ($\approx$ 0.80 for democracy discourse and $\approx$ 0.83 for election fraud discourse) emphasize the substantial explanatory power of these variables in predicting logged retweet counts. This reinforces past studies which show how Twitter content is amplified through distinct networks and endorsement signals rapidly spread and echo information on social platforms [@brady2019effective; @papacharissi2012affective]. 

One critical finding of this research is the role political discourse plays in retweet-to-like ratio predicting engagement. Aligning with our hypothesis, retweet-to-like ratios are strong, significant predictors of engagement, but the difference in their effects are substantial between discourse spaces. In our models, the direct effect of retweet-to-like ratios varied across democracy and election fraud discourses when interaction terms were introduced. However, this effect did not equally present itself across different political discourses. Retweet-to-like ratios in election fraud discourse was more directly related to driving engagement than retweet-to-like ratios were in democracy discourse (in model 4, from (0.676 HS) in democracy discourse to  (0.936 HS) in election fraud discourse), indicating drives in engagement of election fraud narratives were more directly influenced by controversy, while in democracy discourse, the influence of controversy driving engagement was spread out across other contextual factors of tweets and user interactions. 

Our models also revealed distinct emotional dynamics of both discourses. In pro-democracy discourse, we found positive sentiment widespread in mentions of either Trump, Biden, or of neither of the candidates. We saw in democracy models suggested that positive controversial references to Trump within the pro-democracy context was engaging content (0.102 HS). This was also seen graphically in @fig-1. This could be partly a result of parody accounts that use Trump name ironically, while talking about or signalling pro-democracy messages. The same pattern is not found for Biden mentions in election fraud discourse, and positive Trump mentions, as well as any positive sentiment, had more difficulty drawing engagement than in democracy discourse. This finding shows how different political ideological spaces can have distinct emotional dynamics, and that controversy, and controversy which fuels engagement, does not always rely on negative sentiment, consistent with themes in H2.

Our study does have limitations: data was collected through the keyword "Biden" and "Trump," and was limited to approximately one month of data. Additionally, for analysis, data was subsetted into two distinct groups such that there would be no overlap in narratives and mentions of candidates. Such methods have limited the scope of analysis, and we do not take into account the broader, long-term, and relevant discussions surrounding our study. While our heuristic bot cleaning method proved effective [@inuwa2018lexical], a more sophisticated approach could further clean and strengthen the data. Future research could develop and expand on these cleaning methods, as well as collect a complete picture of the metadata of the tweet objects. More advanced methods are needed to more accurately track the deep semantics contained within the core text of tweets and within networks between users. 

In conclusion, our results provide robust quantitative findings of how controversy and emotional factors drive engagement in distinct political narratives during a pivotal, politically engaged moment in the US. The findings of this paper contribute to a insightful perspective on how structural dynamics of engagement in political discourse function in a social media space. 
